---
phase: 13-hybrid-search-reranking
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/embedding/chunker.ts
  - src/lib/embedding/vector-store.ts
autonomous: true
requirements:
  - RAGQ-01
  - RAGQ-03

must_haves:
  truths:
    - "chunkDocumentParentChild() produces PARENT chunks (~8000 chars) and CHILD chunks (~2000 chars) with correct nesting"
    - "insertParentChildChunks() stores PARENT rows (no embedding) and CHILD rows (with embedding + parentChunkId FK)"
    - "searchSimilar() excludes PARENT chunks (WHERE chunkType != 'PARENT') and returns chunkType + parentChunkId fields"
    - "fetchParentContent() returns parent content for CHILD chunk IDs via JOIN in a single query"
    - "Existing STANDALONE chunks are not affected — they pass through searchSimilar unchanged"
  artifacts:
    - path: "src/lib/embedding/chunker.ts"
      provides: "chunkDocumentParentChild() alongside existing chunkDocument()"
      exports: ["chunkDocument", "createLegalTextSplitter", "chunkDocumentParentChild"]
    - path: "src/lib/embedding/vector-store.ts"
      provides: "insertParentChildChunks(), fetchParentContent(), updated SearchResult with chunkType + parentChunkId"
      exports: ["insertChunks", "insertParentChildChunks", "deleteChunks", "searchSimilar", "fetchParentContent", "SearchResult", "getEmbeddingStats"]
  key_links:
    - from: "src/lib/embedding/vector-store.ts"
      to: "prisma/schema.prisma"
      via: "raw SQL INSERT with chunkType and parentChunkId columns (added in Phase 12)"
      pattern: "chunkType.*PARENT|parentChunkId"
    - from: "src/lib/embedding/chunker.ts"
      to: "src/lib/embedding/vector-store.ts"
      via: "chunkDocumentParentChild output fed into insertParentChildChunks by embedding.processor (Plan 03)"
      pattern: "chunkDocumentParentChild"
---

<objective>
Upgrade `chunker.ts` and `vector-store.ts` to support the parent-child chunking scheme introduced in Phase 12's schema. These files run in Wave 1 (parallel with Plan 01's new library files).

Purpose: The embedding processor (Plan 03) and hybrid-search orchestrator (Plan 01) both depend on these upgraded primitives. Completing them in Wave 1 unblocks Wave 2 wiring.

Output: `chunker.ts` gains `chunkDocumentParentChild()`. `vector-store.ts` gains `insertParentChildChunks()`, `fetchParentContent()`, and updated `searchSimilar()` with `chunkType` filtering and additional fields on `SearchResult`.
</objective>

<execution_context>
@/Users/patrickbaumfalk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrickbaumfalk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/13-hybrid-search-reranking/13-RESEARCH.md

<interfaces>
<!-- Current state of files being modified — read before editing. -->

Current src/lib/embedding/chunker.ts exports:
```typescript
export function createLegalTextSplitter(): RecursiveCharacterTextSplitter
export async function chunkDocument(text: string): Promise<{ content: string; index: number }[]>
// Uses GERMAN_LEGAL_SEPARATORS, chunkSize: 1000, chunkOverlap: 200
```

Current src/lib/embedding/vector-store.ts exports:
```typescript
export interface SearchResult {
  content: string;
  dokumentId: string;
  dokumentName: string;
  akteAktenzeichen: string;
  akteBeschreibung: string;
  score: number;
  chunkIndex: number;
}

export async function insertChunks(
  dokumentId: string,
  chunks: { content: string; index: number; embedding: number[] }[],
  modelVersion: string
): Promise<void>

export async function deleteChunks(dokumentId: string): Promise<void>

export async function searchSimilar(
  queryEmbedding: number[],
  opts: SearchOptions
): Promise<SearchResult[]>

export async function getEmbeddingStats(): Promise<{ totalChunks, documentsWithEmbeddings, modelVersions }>
```

Phase 12 schema additions (already in DB):
```sql
-- document_chunks table now has:
-- "chunkType" ChunkType NOT NULL DEFAULT 'STANDALONE'   (enum: STANDALONE, PARENT, CHILD)
-- "parentChunkId" UUID REFERENCES document_chunks(id) ON DELETE CASCADE  (nullable)
```

From pgvector npm:
```typescript
import pgvector from "pgvector";
const vectorSql = pgvector.toSql(embedding); // converts number[] to SQL-safe format
// Used as: ${vectorSql}::vector in raw SQL
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add chunkDocumentParentChild to chunker.ts</name>
  <files>src/lib/embedding/chunker.ts</files>
  <action>
Read current `src/lib/embedding/chunker.ts` first. Then ADD the following without removing anything existing (preserve `createLegalTextSplitter()` and `chunkDocument()` unchanged — they are used by existing STANDALONE pipeline).

Add `chunkDocumentParentChild()` function:

```typescript
/**
 * Chunk a document into parent-child pairs for RAG.
 *
 * Parent chunks (~2000 tokens = ~8000 chars for German legal text) are stored
 * unembedded as context retrieval units. Child chunks (~500 tokens = ~2000 chars)
 * are embedded and used as retrieval units.
 *
 * Returns an empty array if the text is empty or whitespace-only.
 */
export async function chunkDocumentParentChild(text: string): Promise<{
  parent: { content: string; index: number };
  children: { content: string; index: number }[];
}[]> {
  const trimmed = text.trim();
  if (!trimmed) return [];

  // Step 1: Split into PARENT chunks (~2000 tokens = ~8000 chars for German)
  const parentSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 8000,
    chunkOverlap: 400,
    separators: GERMAN_LEGAL_SEPARATORS,
  });
  const parentTexts = await parentSplitter.splitText(trimmed);

  // Step 2: For each parent, split into CHILD chunks (~500 tokens = ~2000 chars)
  const childSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 2000,
    chunkOverlap: 200,
    separators: GERMAN_LEGAL_SEPARATORS,
  });

  const results: {
    parent: { content: string; index: number };
    children: { content: string; index: number }[];
  }[] = [];
  let globalChildIndex = 0;

  for (let parentIndex = 0; parentIndex < parentTexts.length; parentIndex++) {
    const childTexts = await childSplitter.splitText(parentTexts[parentIndex]);
    results.push({
      parent: { content: parentTexts[parentIndex], index: parentIndex },
      children: childTexts.map((c) => ({ content: c, index: globalChildIndex++ })),
    });
  }

  return results;
}
```

Do NOT modify `GERMAN_LEGAL_SEPARATORS`, `createLegalTextSplitter()`, or `chunkDocument()`. The existing STANDALONE pipeline continues using `chunkDocument()`.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer && npx tsc --noEmit --skipLibCheck 2>&1 | grep -E "chunker|error TS" | head -10</automated>
  </verify>
  <done>chunker.ts exports chunkDocumentParentChild alongside existing functions, TypeScript compiles without errors</done>
</task>

<task type="auto">
  <name>Task 2: Upgrade vector-store.ts with parent-child storage and updated search</name>
  <files>src/lib/embedding/vector-store.ts</files>
  <action>
Read current `src/lib/embedding/vector-store.ts` first. Make the following targeted changes:

**Change 1: Extend SearchResult interface** — add `chunkType` and `parentChunkId` fields:
```typescript
export interface SearchResult {
  content: string;
  dokumentId: string;
  dokumentName: string;
  akteAktenzeichen: string;
  akteBeschreibung: string;
  score: number;
  chunkIndex: number;
  chunkType: string;           // NEW: 'STANDALONE' | 'CHILD' | 'PARENT'
  parentChunkId: string | null; // NEW: null for STANDALONE/PARENT, set for CHILD
  id: string;                  // NEW: chunk ID (needed for reranker and parent lookup)
}
```

**Change 2: Update all raw SQL queries in searchSimilar()** — add three fields to every SELECT and add a WHERE filter:
- Add to SELECT: `dc.id, dc."chunkType", dc."parentChunkId"`
- Add to WHERE: `AND dc."chunkType" != 'PARENT'` (exclude parent chunks — they have no embedding and should not appear in search results)
- Update `mapRow` to include: `id: r.id, chunkType: r.chunkType, parentChunkId: r.parentChunkId ?? null`
- Add to RawRow type: `id: string; chunkType: string; parentChunkId: string | null`
- There are 4 query branches in searchSimilar (cross-Akte with/without modelVersion, single-Akte with/without modelVersion) — update ALL of them

**Change 3: Add insertParentChildChunks() function** after existing `insertChunks()`:
```typescript
/**
 * Insert parent-child chunks for a document.
 * PARENT chunks are stored without embedding (context retrieval only).
 * CHILD chunks are stored with embedding + parentChunkId FK.
 * Deletes existing chunks first (idempotent).
 */
export async function insertParentChildChunks(
  dokumentId: string,
  chunks: Array<{
    parent: { content: string; index: number };
    children: Array<{ content: string; index: number; embedding: number[] }>;
  }>,
  modelVersion: string
): Promise<void> {
  // Delete existing chunks first (idempotent re-embedding)
  await deleteChunks(dokumentId);

  for (const group of chunks) {
    // Insert PARENT chunk — no embedding (parents are 2000+ tokens, exceed embedding model limits)
    const parentIdRows = await prisma.$queryRaw<[{ id: string }]>`
      INSERT INTO document_chunks (id, "dokumentId", "chunkIndex", content, embedding, "modelVersion", "createdAt", "chunkType")
      VALUES (gen_random_uuid(), ${dokumentId}, ${group.parent.index}, ${group.parent.content}, NULL, ${modelVersion}, NOW(), 'PARENT')
      RETURNING id
    `;
    const parentChunkId = parentIdRows[0].id;

    // Insert CHILD chunks with embedding and FK to parent
    for (const child of group.children) {
      const vectorSql = pgvector.toSql(child.embedding);
      await prisma.$executeRaw`
        INSERT INTO document_chunks (id, "dokumentId", "chunkIndex", content, embedding, "modelVersion", "createdAt", "chunkType", "parentChunkId")
        VALUES (gen_random_uuid(), ${dokumentId}, ${child.index}, ${child.content}, ${vectorSql}::vector, ${modelVersion}, NOW(), 'CHILD', ${parentChunkId})
      `;
    }
  }
}
```

**Change 4: Add fetchParentContent() function** at the end of the file:
```typescript
/**
 * Fetch parent chunk content for a set of CHILD chunk IDs.
 * Returns a Map from childId -> parentContent.
 * STANDALONE chunks (parentChunkId = NULL) are not returned — caller handles them separately.
 */
export async function fetchParentContent(
  chunkIds: string[]
): Promise<Map<string, string>> {
  if (chunkIds.length === 0) return new Map();

  const rows = await prisma.$queryRaw<
    Array<{ childId: string; parentContent: string }>
  >`
    SELECT dc_child.id AS "childId", dc_parent.content AS "parentContent"
    FROM document_chunks dc_child
    JOIN document_chunks dc_parent ON dc_parent.id = dc_child."parentChunkId"
    WHERE dc_child.id = ANY(${chunkIds})
      AND dc_child."chunkType" = 'CHILD'
      AND dc_parent."chunkType" = 'PARENT'
  `;

  const map = new Map<string, string>();
  rows.forEach((row) => map.set(row.childId, row.parentContent));
  return map;
}
```

Do NOT remove or rename `insertChunks()` — it is still used by the existing STANDALONE embedding pipeline until Plan 03 switches the processor. The functions coexist.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer && npx tsc --noEmit --skipLibCheck 2>&1 | grep -E "vector-store|error TS" | head -20</automated>
  </verify>
  <done>vector-store.ts exports insertParentChildChunks and fetchParentContent, SearchResult has id + chunkType + parentChunkId fields, searchSimilar filters PARENT chunks in all 4 query branches, TypeScript compiles without errors</done>
</task>

</tasks>

<verification>
Run full TypeScript check: `cd /Users/patrickbaumfalk/Projekte/AI-Lawyer && npx tsc --noEmit --skipLibCheck 2>&1 | head -30`

Verify searchSimilar still works for callers that don't use new fields (backward compatible — added fields, not removed). Confirm PARENT filter is in all 4 SQL branches by grepping: `grep -c "chunkType.*PARENT" src/lib/embedding/vector-store.ts`
</verification>

<success_criteria>
- `src/lib/embedding/chunker.ts` exports `chunkDocumentParentChild()` alongside all original exports unchanged
- `src/lib/embedding/vector-store.ts` exports `insertParentChildChunks()` and `fetchParentContent()`
- `SearchResult` interface has `id`, `chunkType`, `parentChunkId` fields
- All 4 `searchSimilar()` query branches include `AND dc."chunkType" != 'PARENT'` and return the new fields
- TypeScript compilation succeeds with no errors in these files
- `insertChunks()` still present and unchanged (used by STANDALONE pipeline until Plan 03)
</success_criteria>

<output>
After completion, create `.planning/phases/13-hybrid-search-reranking/13-02-SUMMARY.md`
</output>
