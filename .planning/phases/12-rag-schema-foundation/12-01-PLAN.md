---
phase: 12-rag-schema-foundation
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - prisma/schema.prisma
  - prisma/migrations/manual_rag_hnsw_indexes.sql
autonomous: true
requirements:
  - RAGQ-02

must_haves:
  truths:
    - "prisma migrate deploy runs without errors — all five new tables exist in the DB (law_chunks, urteil_chunks, muster, muster_chunks, akte_normen)"
    - "Existing document_chunks rows have chunkType = 'STANDALONE' — no NULL values in the chunkType column"
    - "Drei HNSW-Index-Objekte existieren in pg_indexes — law_chunks_embedding_hnsw, urteil_chunks_embedding_hnsw, muster_chunks_embedding_hnsw — Vektor-Ähnlichkeitsabfragen nutzen den Index sobald Daten vorhanden sind"
    - "npx prisma generate succeeds — TypeScript client exposes LawChunk, UrteilChunk, Muster, MusterChunk, AkteNorm, ChunkType, MusterNerStatus without runtime errors"
    - "npx prisma validate passes with zero errors before running migrate dev"
  artifacts:
    - path: "prisma/schema.prisma"
      provides: "ChunkType enum, MusterNerStatus enum, extended DocumentChunk, 5 new models (LawChunk, UrteilChunk, Muster, MusterChunk, AkteNorm), back-relations on User and Akte"
      contains: "ChunkType"
    - path: "prisma/migrations/manual_rag_hnsw_indexes.sql"
      provides: "HNSW index DDL for law_chunks, urteil_chunks, muster_chunks embedding columns"
      contains: "law_chunks_embedding_hnsw"
    - path: "prisma/migrations/*_add_rag_schema_foundation/migration.sql"
      provides: "Auto-generated additive DDL — CREATE TYPE, CREATE TABLE, ALTER TABLE for document_chunks"
      contains: "ChunkType"
  key_links:
    - from: "prisma/schema.prisma (DocumentChunk.chunkType)"
      to: "document_chunks table column"
      via: "prisma migrate dev"
      pattern: "NOT NULL DEFAULT 'STANDALONE'"
    - from: "prisma/schema.prisma (AkteNorm.akteId)"
      to: "akten table"
      via: "FK + back-relation normen AkteNorm[] on model Akte"
      pattern: "normen.*AkteNorm"
    - from: "prisma/migrations/manual_rag_hnsw_indexes.sql"
      to: "law_chunks.embedding, urteil_chunks.embedding, muster_chunks.embedding"
      via: "psql -f or docker entrypoint"
      pattern: "USING hnsw.*vector_cosine_ops"
---

<objective>
Add all Prisma schema foundations required by the RAG pipeline: extend DocumentChunk with parent-child chunking support, add five new models (LawChunk, UrteilChunk, Muster, MusterChunk, AkteNorm), create and apply the Prisma migration, then create and apply HNSW vector indexes for the three new chunk tables.

Purpose: Every subsequent phase (13-18) writes data to these tables. Without this schema, no RAG data can be stored and no retrieval can happen.
Output: Updated prisma/schema.prisma, an auto-generated Prisma migration SQL file applied to the running DB, manual_rag_hnsw_indexes.sql applied to the DB, and a regenerated Prisma client with all new types.
</objective>

<execution_context>
@/Users/patrickbaumfalk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrickbaumfalk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-rag-schema-foundation/12-RESEARCH.md

<interfaces>
<!-- Existing Prisma models the executor must extend or relate to. Extracted directly from prisma/schema.prisma. -->

From prisma/schema.prisma (current DocumentChunk model — to be extended):
```prisma
model DocumentChunk {
  id           String   @id @default(cuid())
  dokumentId   String
  dokument     Dokument @relation(fields: [dokumentId], references: [id], onDelete: Cascade)
  chunkIndex   Int
  content      String   @db.Text
  embedding    Unsupported("vector(1024)")?
  modelVersion String
  createdAt    DateTime @default(now())

  @@unique([dokumentId, chunkIndex])
  @@index([dokumentId])
  @@map("document_chunks")
}
```

From prisma/schema.prisma (current User model relations section — append new back-relations here):
```prisma
model User {
  id            String    @id @default(cuid())
  // ...existing fields...
  // Relations (existing, partial):
  aktenAlsAnwalt        Akte[]           @relation("AnwaltAkten")
  aktenAlsSachbearbeiter Akte[]          @relation("SachbearbeiterAkten")
  // ...many more existing relations at lines 354-392...
  @@map("users")
}
```

From prisma/schema.prisma (current Akte model relations section — append normen back-relation):
```prisma
model Akte {
  id               String      @id @default(cuid())
  // ...existing fields...
  // Relations (existing, partial):
  beteiligte        Beteiligter[]
  dokumente         Dokument[]
  // ...many more existing relations at lines 690-708...
  @@index([status])
  @@index([anwaltId])
  @@index([sachgebiet])
  @@map("akten")
}
```

From prisma/migrations/manual_pgvector_index.sql (existing HNSW index pattern to replicate):
```sql
CREATE INDEX IF NOT EXISTS document_chunks_embedding_idx
  ON document_chunks
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend prisma/schema.prisma and run prisma migrate dev</name>
  <files>prisma/schema.prisma</files>
  <action>
Make the following additive changes to prisma/schema.prisma. Do NOT remove or modify any existing content except adding fields/relations to DocumentChunk, User, and Akte.

**Step 1 — Add two enums** after the existing enum section (before or near the DocumentChunk model):

```prisma
enum ChunkType {
  STANDALONE
  PARENT
  CHILD
}

enum MusterNerStatus {
  PENDING_NER
  NER_RUNNING
  INDEXED
  REJECTED_PII_DETECTED
}
```

**Step 2 — Extend DocumentChunk model** (replace the existing model, preserving all original fields):

```prisma
model DocumentChunk {
  id           String    @id @default(cuid())
  dokumentId   String
  dokument     Dokument  @relation(fields: [dokumentId], references: [id], onDelete: Cascade)
  chunkIndex   Int
  content      String    @db.Text
  embedding    Unsupported("vector(1024)")?
  modelVersion String
  createdAt    DateTime  @default(now())
  // Phase 12: Parent-child chunking
  chunkType     ChunkType   @default(STANDALONE)
  parentChunkId String?
  parentChunk   DocumentChunk?  @relation("DocumentChunkParent", fields: [parentChunkId], references: [id], onDelete: SetNull)
  childChunks   DocumentChunk[] @relation("DocumentChunkParent")

  @@unique([dokumentId, chunkIndex])
  @@index([dokumentId])
  @@index([parentChunkId])
  @@map("document_chunks")
}
```

**Step 3 — Add five new models** after DocumentChunk:

```prisma
model LawChunk {
  id            String    @id @default(cuid())
  gesetzKuerzel String
  paragraphNr   String
  titel         String
  content       String    @db.Text
  parentContent String?   @db.Text
  embedding     Unsupported("vector(1024)")?
  modelVersion  String
  syncedAt      DateTime  @default(now())
  sourceUrl     String?

  @@index([gesetzKuerzel])
  @@index([paragraphNr])
  @@map("law_chunks")
}

model UrteilChunk {
  id            String    @id @default(cuid())
  aktenzeichen  String
  gericht       String
  datum         DateTime
  rechtsgebiet  String?
  content       String    @db.Text
  parentContent String?   @db.Text
  embedding     Unsupported("vector(1024)")?
  modelVersion  String
  sourceUrl     String    @unique
  piiFiltered   Boolean   @default(false)
  ingestedAt    DateTime  @default(now())

  @@index([gericht])
  @@index([datum])
  @@index([rechtsgebiet])
  @@map("urteil_chunks")
}

model Muster {
  id           String          @id @default(cuid())
  name         String
  kategorie    String
  beschreibung String?         @db.Text
  minioKey     String
  mimeType     String
  nerStatus    MusterNerStatus @default(PENDING_NER)
  uploadedById String
  uploadedBy   User            @relation("MusterUploads", fields: [uploadedById], references: [id])
  createdAt    DateTime        @default(now())
  updatedAt    DateTime        @updatedAt
  chunks       MusterChunk[]

  @@index([nerStatus])
  @@map("muster")
}

model MusterChunk {
  id            String    @id @default(cuid())
  musterId      String
  muster        Muster    @relation(fields: [musterId], references: [id], onDelete: Cascade)
  chunkIndex    Int
  content       String    @db.Text
  parentContent String?   @db.Text
  embedding     Unsupported("vector(1024)")?
  modelVersion  String
  createdAt     DateTime  @default(now())

  @@unique([musterId, chunkIndex])
  @@index([musterId])
  @@map("muster_chunks")
}

model AkteNorm {
  id            String   @id @default(cuid())
  akteId        String
  akte          Akte     @relation(fields: [akteId], references: [id], onDelete: Cascade)
  gesetzKuerzel String
  paragraphNr   String
  anmerkung     String?  @db.Text
  addedById     String
  addedBy       User     @relation("AkteNormUser", fields: [addedById], references: [id])
  createdAt     DateTime @default(now())

  @@unique([akteId, gesetzKuerzel, paragraphNr])
  @@index([akteId])
  @@map("akte_normen")
}
```

**Step 4 — Add back-relations to model User** (inside the existing User model, in the Relations section, add after existing relations):

```prisma
  akteNormen    AkteNorm[] @relation("AkteNormUser")
  musterUploads Muster[]   @relation("MusterUploads")
```

**Step 5 — Add back-relation to model Akte** (inside the existing Akte model, in the Relations section, add after existing relations):

```prisma
  normen  AkteNorm[]
```

**Step 6 — Validate and migrate:**

Run in order:
```bash
cd /Users/patrickbaumfalk/Projekte/AI-Lawyer
npx prisma validate
```
If validate fails, fix schema errors (most common: missing relation name on self-relation, missing back-relation). Do NOT proceed until validate passes.

Then generate migration:
```bash
npx prisma migrate dev --name add_rag_schema_foundation
```

**CRITICAL: Before the migration runs, inspect the generated migration.sql** in `prisma/migrations/YYYYMMDDHHMMSS_add_rag_schema_foundation/migration.sql`. Verify it contains BOTH of these lines for document_chunks:
```sql
ALTER TABLE "document_chunks" ADD COLUMN     "chunkType" "ChunkType" NOT NULL DEFAULT 'STANDALONE';
ALTER TABLE "document_chunks" ADD COLUMN     "parentChunkId" TEXT;
```
If chunkType has a different DEFAULT or is nullable, edit the migration.sql to fix it before allowing `migrate dev` to apply it. The `migrate dev` command will pause and ask if you want to apply the migration — confirm yes.

Finally regenerate the client:
```bash
npx prisma generate
```
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer && npx prisma validate 2>&amp;1 | tail -5 &amp;&amp; npx prisma migrate status 2>&amp;1 | tail -10</automated>
  </verify>
  <done>
    - `npx prisma validate` exits with zero errors
    - `npx prisma migrate status` shows "Database schema is up to date"
    - All 5 new tables exist in the database (law_chunks, urteil_chunks, muster, muster_chunks, akte_normen)
    - `SELECT COUNT(*) FROM document_chunks WHERE "chunkType" IS NULL` returns 0
    - `npx prisma generate` succeeds (TypeScript client includes ChunkType, MusterNerStatus, LawChunk, UrteilChunk, Muster, MusterChunk, AkteNorm)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create and apply HNSW vector indexes for new chunk tables</name>
  <files>prisma/migrations/manual_rag_hnsw_indexes.sql</files>
  <action>
Create a new file `prisma/migrations/manual_rag_hnsw_indexes.sql` with HNSW index DDL for the three new chunk tables. This file follows the exact same pattern as the existing `prisma/migrations/manual_pgvector_index.sql`.

**File content:**

```sql
-- ============================================================================
-- HNSW Indexes for RAG Schema Foundation (Phase 12)
-- ============================================================================
-- Run after prisma migrate deploy to create vector similarity indexes.
-- Prisma cannot generate HNSW indexes — these are applied manually.
--
-- Apply via: psql -U <user> -d <db> -f prisma/migrations/manual_rag_hnsw_indexes.sql
-- Or include in the Docker entrypoint / startup script alongside manual_pgvector_index.sql.
--
-- Parameters: m=16 (connections per layer), ef_construction=64 (build accuracy)
-- Matches existing document_chunks_embedding_idx parameters exactly.
-- ============================================================================

-- Gesetze chunks
CREATE INDEX IF NOT EXISTS law_chunks_embedding_hnsw
  ON law_chunks
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- Urteil chunks
CREATE INDEX IF NOT EXISTS urteil_chunks_embedding_hnsw
  ON urteil_chunks
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);

-- Muster chunks
CREATE INDEX IF NOT EXISTS muster_chunks_embedding_hnsw
  ON muster_chunks
  USING hnsw (embedding vector_cosine_ops)
  WITH (m = 16, ef_construction = 64);
```

After writing the file, apply it to the running database. Find the DB connection URL from the environment (check `.env` or `.env.local` for DATABASE_URL):

```bash
cd /Users/patrickbaumfalk/Projekte/AI-Lawyer
# Apply the HNSW indexes
psql "$DATABASE_URL" -f prisma/migrations/manual_rag_hnsw_indexes.sql
```

If psql is not available locally but the database runs in Docker, apply via docker exec:
```bash
# Alternative if running via Docker Compose
docker compose exec db psql -U postgres -d ai_lawyer -f /dev/stdin < prisma/migrations/manual_rag_hnsw_indexes.sql
```

After applying, verify each index exists and is used by the query planner. Run the following EXPLAIN ANALYZE check for each table (use a zero-vector placeholder since tables are empty — the planner still resolves the index):

```sql
-- Run against the live DB to verify index scan (not seq scan)
EXPLAIN SELECT id FROM law_chunks ORDER BY embedding <=> '[0.1,0.2,0.3]'::vector LIMIT 1;
EXPLAIN SELECT id FROM urteil_chunks ORDER BY embedding <=> '[0.1,0.2,0.3]'::vector LIMIT 1;
EXPLAIN SELECT id FROM muster_chunks ORDER BY embedding <=> '[0.1,0.2,0.3]'::vector LIMIT 1;
```

Note: On empty tables the planner may choose Seq Scan (0 rows = no cost difference). The key verification is that the index OBJECTS exist in pg_indexes, not necessarily that EXPLAIN uses them on an empty table.

Verify index existence:
```sql
SELECT indexname, tablename FROM pg_indexes
WHERE indexname IN (
  'law_chunks_embedding_hnsw',
  'urteil_chunks_embedding_hnsw',
  'muster_chunks_embedding_hnsw'
);
```
All three must appear.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer &amp;&amp; source .env 2>/dev/null || true; psql "${DATABASE_URL}" -c "SELECT indexname FROM pg_indexes WHERE indexname IN ('law_chunks_embedding_hnsw','urteil_chunks_embedding_hnsw','muster_chunks_embedding_hnsw') ORDER BY indexname;" 2>&amp;1</automated>
  </verify>
  <done>
    - `prisma/migrations/manual_rag_hnsw_indexes.sql` exists with HNSW DDL for all three tables
    - `SELECT indexname FROM pg_indexes WHERE indexname IN (...)` returns all three index names
    - No errors during psql application of the SQL file
  </done>
</task>

</tasks>

<verification>
End-to-end verification after both tasks complete:

1. Schema integrity:
   ```bash
   npx prisma validate
   ```
   Must exit with zero errors.

2. Migration status:
   ```bash
   npx prisma migrate status
   ```
   Must show "Database schema is up to date".

3. Backfill check (existing rows are STANDALONE, not NULL):
   ```sql
   SELECT COUNT(*) FROM document_chunks WHERE "chunkType" IS NULL;
   -- Expected: 0
   SELECT COUNT(*) FROM document_chunks WHERE "chunkType" = 'STANDALONE';
   -- Expected: same count as total document_chunks rows
   ```

4. New tables exist:
   ```sql
   SELECT table_name FROM information_schema.tables
   WHERE table_name IN ('law_chunks','urteil_chunks','muster','muster_chunks','akte_normen')
   ORDER BY table_name;
   -- Expected: all 5 rows returned
   ```

5. HNSW indexes exist:
   ```sql
   SELECT indexname FROM pg_indexes
   WHERE indexname IN (
     'law_chunks_embedding_hnsw',
     'urteil_chunks_embedding_hnsw',
     'muster_chunks_embedding_hnsw'
   );
   -- Expected: all 3 rows returned
   ```

6. TypeScript client includes new types:
   ```bash
   npx tsc --noEmit 2>&1 | grep -c "error" || echo "0 errors"
   ```
</verification>

<success_criteria>
- `prisma migrate deploy` runs without errors in a clean environment — all 5 new tables exist
- `SELECT COUNT(*) FROM document_chunks WHERE "chunkType" IS NULL` returns 0
- All three HNSW indexes (law_chunks_embedding_hnsw, urteil_chunks_embedding_hnsw, muster_chunks_embedding_hnsw) appear in pg_indexes
- `npx prisma generate` produces a client where `import { ChunkType, MusterNerStatus, LawChunk, UrteilChunk, Muster, MusterChunk, AkteNorm } from '@prisma/client'` resolves without TypeScript errors
- `npx prisma validate` exits clean
</success_criteria>

<output>
After completion, create `.planning/phases/12-rag-schema-foundation/12-01-SUMMARY.md` with what was built, key decisions made, and any deviations from this plan.
</output>
