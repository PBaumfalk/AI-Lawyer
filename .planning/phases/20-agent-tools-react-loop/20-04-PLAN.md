---
phase: 20-agent-tools-react-loop
plan: 04
type: execute
wave: 4
depends_on: ["20-01", "20-02", "20-03"]
files_modified:
  - src/lib/helena/__tests__/tools.test.ts
  - src/lib/helena/__tests__/orchestrator.test.ts
autonomous: true
requirements: [AGNT-01, AGNT-02, AGNT-03, AGNT-04, AGNT-05, AGNT-06]

must_haves:
  truths:
    - "Unit tests verify each tool factory function returns a valid AI SDK tool with correct schema and behavior"
    - "Unit tests verify role-filter, tool-cache, stall-detector, token-budget, and rate-limiter modules"
    - "Integration test verifies the full ReAct loop with a mock LLM that returns tool calls and text"
    - "All tests pass with vitest and use mocked Prisma (no real DB needed)"
  artifacts:
    - path: "src/lib/helena/__tests__/tools.test.ts"
      provides: "Unit tests for tool factory functions and supporting infrastructure"
      min_lines: 150
    - path: "src/lib/helena/__tests__/orchestrator.test.ts"
      provides: "Integration tests for ReAct loop with mock LLM responses"
      min_lines: 100
  key_links:
    - from: "src/lib/helena/__tests__/tools.test.ts"
      to: "src/lib/helena/tools/index.ts"
      via: "createHelenaTools import"
      pattern: "createHelenaTools"
    - from: "src/lib/helena/__tests__/orchestrator.test.ts"
      to: "src/lib/helena/orchestrator.ts"
      via: "runAgent import"
      pattern: "runAgent"
---

<objective>
Create unit tests for Helena tool factory functions with mocked Prisma, and integration tests for the ReAct loop with mock LLM responses.

Purpose: Implements the locked CONTEXT.md decisions: "Unit tests per tool factory function with mocked Prisma" and "Integration tests for ReAct loop with mock LLM responses." Ensures the entire Helena library is verified beyond TypeScript compilation.

Output: Two test files covering tools and orchestrator, all passing via `vitest`.
</objective>

<execution_context>
@/Users/patrickbaumfalk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrickbaumfalk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-agent-tools-react-loop/20-RESEARCH.md
@.planning/phases/20-agent-tools-react-loop/20-01-SUMMARY.md
@.planning/phases/20-agent-tools-react-loop/20-02-SUMMARY.md
@.planning/phases/20-agent-tools-react-loop/20-03-SUMMARY.md

<interfaces>
<!-- From Plans 01-03 outputs -->

From src/lib/helena/tools/types.ts (Plan 01):
```typescript
export interface ToolContext {
  prisma: PrismaClient;
  userId: string;
  userRole: UserRole;
  akteId: string | null;
  akteAccessFilter: Record<string, any>;
  helenaUserId: string;
  cache: ToolCache;
  abortSignal?: AbortSignal;
}
```

From src/lib/helena/tools/index.ts (Plan 01):
```typescript
export function createHelenaTools(options: CreateHelenaToolsOptions): Record<string, CoreTool>;
```

From src/lib/helena/role-filter.ts (Plan 01):
```typescript
export function filterToolsByRole(tools: Record<string, any>, role: UserRole): Record<string, any>;
```

From src/lib/helena/tool-cache.ts (Plan 01):
```typescript
export function createToolCache(): ToolCache;
export function createCacheKey(toolName: string, params: Record<string, unknown>): string;
```

From src/lib/helena/orchestrator.ts (Plan 02):
```typescript
export function runAgent(options: AgentRunOptions): Promise<AgentRunResult>;
```

From src/lib/helena/stall-detector.ts (Plan 02):
```typescript
export function createStallDetector(): StallDetector;
```

From src/lib/helena/token-budget.ts (Plan 02):
```typescript
export function estimateTokens(text: string): number;
export function truncateMessages(messages: CoreMessage[], contextWindow: number, budgetPercent?: number): CoreMessage[];
```

From src/lib/helena/rate-limiter.ts (Plan 03):
```typescript
export function checkRateLimit(options: { userId: string; prisma: PrismaClient }): Promise<RateLimitResult>;
```

From src/lib/helena/index.ts (Plan 03):
```typescript
export function runHelenaAgent(options: HelenaAgentOptions): Promise<HelenaAgentResult>;
```

From vitest (already in devDependencies):
```typescript
import { describe, it, expect, vi, beforeEach } from "vitest";
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Unit tests for tool factory functions and infrastructure</name>
  <files>
    src/lib/helena/__tests__/tools.test.ts
  </files>
  <action>
Create `src/lib/helena/__tests__/tools.test.ts` with unit tests using vitest and mocked Prisma.

**Test setup:**
- Mock `@prisma/client` using `vi.mock` -- create a mock PrismaClient with `vi.fn()` stubs for all Prisma methods used by tools (akte.findFirst, dokument.findMany, helenaDraft.create, etc.)
- Create a helper `createMockToolContext()` that returns a ToolContext with the mock Prisma, a test userId, ADMIN role, test akteId, empty akteAccessFilter, test helenaUserId, and a fresh `createToolCache()` instance
- Mock `generateQueryEmbedding` from `@/lib/embedding/embedder` (return a fixed embedding vector)
- Mock `searchLawChunks`, `searchUrteilChunks`, `searchMusterChunks` from their respective modules (return canned results)
- Mock `computeRvgFee` and `buildCalculation` from `@/lib/finance/rvg/calculator`

**Test groups:**

1. **describe("createHelenaTools"):**
   - "returns a Record with all expected tool names" -- call factory, check keys include read_akte, search_gesetze, create_draft_dokument, etc.
   - "tool names use snake_case derived from filenames" -- verify no dashes in keys
   - "returns only tools allowed for role" -- call with SEKRETARIAT role, verify only read tools + create_notiz are present, no update_akte_rag

2. **describe("filterToolsByRole"):**
   - "ADMIN gets all tools"
   - "ANWALT gets all tools"
   - "SACHBEARBEITER gets read + limited write (no update_akte_rag)"
   - "SEKRETARIAT gets read + create_notiz only"

3. **describe("read tools"):**
   - "read_akte returns summary data" -- mock akte.findFirst to return a test Akte, call tool.execute, verify result has expected shape
   - "read_akte returns error when no akteId" -- call with no akteId and no context, verify error message
   - "read_akte applies akteAccessFilter in WHERE" -- verify mock was called with filter in where clause
   - "search_gesetze calls generateQueryEmbedding then searchLawChunks" -- verify call chain
   - "search_gesetze returns error when embedding fails" -- mock embedding to throw, verify graceful error

4. **describe("write tools"):**
   - "create_draft_dokument creates HelenaDraft with PENDING status" -- mock helenaDraft.create, verify data.typ === "DOKUMENT" and data.status === "PENDING"
   - "create_alert creates HelenaAlert directly" -- verify it calls helenaAlert.create, NOT helenaDraft.create
   - "create_notiz works without akteId" -- verify no error when both akteId param and ctx.akteId are null

5. **describe("tool-cache"):**
   - "createCacheKey produces deterministic keys for same params in different order"
   - "cache.has returns false for unseen key, true after set"

6. **describe("stall-detector"):**
   - "isStalled returns false initially"
   - "isStalled returns true after duplicate call (same tool + same params 2x)"
   - "isStalled returns true after 3 consecutive identical results"
   - "isStalled returns false for same tool with different params"
   - "getForceMessage returns German message"

7. **describe("token-budget"):**
   - "estimateTokens returns reasonable estimate" -- "hello" should be ~2 tokens
   - "truncateMessages preserves system and first user message"
   - "truncateMessages removes oldest tool results when over budget"
   - "truncateMessages returns unchanged if under budget"

8. **describe("rate-limiter"):**
   - Mock ioredis -- create a mock Redis client that returns incrementing counter values
   - "checkRateLimit allows request when under limit"
   - "checkRateLimit rejects request when over limit with German message"
   - "checkRateLimit fails open when Redis unavailable" -- mock Redis to throw, verify allowed: true

Use `vi.mock()` for module mocking, `vi.fn()` for individual function mocks, `beforeEach` to reset mocks between tests.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer/.claude/worktrees/dynamic-sleeping-dream && npx vitest run src/lib/helena/__tests__/tools.test.ts --reporter=verbose 2>&1 | tail -30</automated>
  </verify>
  <done>
    - tools.test.ts exists with 20+ test cases across 8 describe blocks
    - All tool factory tests use mocked Prisma (no real DB)
    - Role filter tests verify all 4 role tiers
    - Read tool tests verify RBAC filter application and error handling
    - Write tool tests verify HelenaDraft creation with PENDING status
    - Infrastructure tests cover cache, stall-detector, token-budget, and rate-limiter
    - All tests pass via vitest
  </done>
</task>

<task type="auto">
  <name>Task 2: Integration tests for ReAct loop with mock LLM</name>
  <files>
    src/lib/helena/__tests__/orchestrator.test.ts
  </files>
  <action>
Create `src/lib/helena/__tests__/orchestrator.test.ts` with integration tests using vitest and a mock LLM.

**Mock LLM setup:**
- Create a `createMockModel()` helper that returns a mock LanguageModel conforming to AI SDK interface
- The mock model should support configurable responses: a sequence of steps that can include text responses and tool calls
- Use `vi.mock("ai", async () => { ... })` to mock `generateText` from the AI SDK -- the mock should:
  1. Accept the same options as real `generateText`
  2. Execute the configured sequence of steps
  3. Call `onStepFinish` after each step
  4. Return the final result in AI SDK format (text, steps, usage, finishReason)
- Alternatively, if mocking `generateText` directly is simpler, create a wrapper that simulates the loop behavior

**Test groups:**

1. **describe("runAgent - basic flow"):**
   - "completes with text response when LLM returns stop" -- mock LLM returns one text step, verify result.text is populated and finishReason is "stop"
   - "executes tool call and returns final text" -- mock LLM sequence: [tool_call(read_akte) -> tool_result -> text("Hier ist die Akte...")], verify steps trace contains toolCall and toolResult entries
   - "respects maxSteps for inline mode (5)" -- verify mode "inline" caps at 5 steps
   - "respects maxSteps for background mode (20)" -- verify mode "background" caps at 20 steps

2. **describe("runAgent - stall detection"):**
   - "detects stall and sets finishReason to stall" -- mock LLM to call same tool with same params twice, verify result.stalled === true and finishReason === "stall"
   - "injects force message when stall detected" -- verify the German force message appears in the context

3. **describe("runAgent - token budget"):**
   - "truncates messages when approaching budget" -- mock a sequence with many large tool results, verify result.truncated === true

4. **describe("runAgent - error handling"):**
   - "returns timeout finishReason on timeout" -- set a very short timeout, mock a slow LLM, verify finishReason === "timeout"
   - "returns abort finishReason on user cancel" -- create AbortController, abort it, verify finishReason === "abort"
   - "returns partial result on error" -- mock LLM to throw, verify result contains error info

5. **describe("runAgent - step updates"):**
   - "calls onStepUpdate after each step" -- provide a vi.fn() callback, verify it was called with correct StepUpdate shape

6. **describe("runHelenaAgent - integration"):**
   - Mock all dependencies (getModel, getHelenaUserId, getProviderName, createHelenaTools, buildSystemPrompt, runAgent, checkRateLimit, classifyComplexity)
   - "returns rate limit error when rate limited" -- mock checkRateLimit to return allowed: false, verify result.rateLimited === true and no agent run happens
   - "classifies complexity and selects mode in auto mode" -- mock classifyComplexity to return background+tier2, verify runAgent is called with mode "background"
   - "uses ollamaResponseGuard for ollama provider" -- mock getProviderName to return "ollama", verify repairToolCall is passed to runAgent

Keep tests focused on behavior, not implementation details. Each test should be self-contained and not depend on test order.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer/.claude/worktrees/dynamic-sleeping-dream && npx vitest run src/lib/helena/__tests__/orchestrator.test.ts --reporter=verbose 2>&1 | tail -30</automated>
  </verify>
  <done>
    - orchestrator.test.ts exists with 12+ test cases across 6 describe blocks
    - Mock LLM simulates multi-step tool calling sequences
    - Basic flow tests verify text response, tool call execution, maxSteps caps
    - Stall detection tests verify duplicate call detection and force message injection
    - Token budget tests verify truncation triggers
    - Error handling tests verify timeout, abort, and error finishReasons
    - runHelenaAgent integration tests verify rate limiting, classification, and guard wiring
    - All tests pass via vitest
  </done>
</task>

</tasks>

<verification>
1. `npx vitest run src/lib/helena/__tests__/ --reporter=verbose` passes all tests
2. No test requires a real database connection or running LLM
3. Tool tests cover all 4 role tiers for filterToolsByRole
4. Orchestrator tests cover stall detection, token budget, and timeout scenarios
5. Rate limiter tests verify both allow and deny paths plus graceful Redis failure
</verification>

<success_criteria>
- `npx vitest run src/lib/helena/__tests__/` reports 30+ passing tests, 0 failures
- Tools test covers: factory output shape, role filtering (4 roles), read tool RBAC, write tool draft creation, cache determinism, stall detection, token budget, rate limiting
- Orchestrator test covers: basic flow, stall detection, token budget truncation, timeout/abort/error handling, step updates, runHelenaAgent integration
- All mocks are properly isolated -- no test pollutes another
</success_criteria>

<output>
After completion, create `.planning/phases/20-agent-tools-react-loop/20-04-SUMMARY.md`
</output>
