---
phase: 04-document-pipeline-ocr-rag-ingestion
plan: 03
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - src/lib/embedding/chunker.ts
  - src/lib/embedding/embedder.ts
  - src/lib/embedding/vector-store.ts
  - src/lib/queue/processors/embedding.processor.ts
  - src/worker.ts
  - src/app/api/search/route.ts
  - src/app/(dashboard)/suche/page.tsx
  - src/components/search/search-page.tsx
  - src/components/search/search-result-card.tsx
  - src/components/layout/command-palette.tsx
  - prisma/migrations/manual_pgvector_index.sql
autonomous: true
requirements:
  - REQ-KI-001

must_haves:
  truths:
    - "Documents are chunked using paragraph-aware splitting for German legal text"
    - "Chunks are embedded via multilingual-e5-large-instruct through Ollama and stored in pgvector"
    - "Embedding model version is tracked per vector so model upgrades are safe"
    - "Embedding pipeline gracefully skips if Ollama is unavailable (logs warning, does not block OCR)"
    - "Search results show rich snippets with highlighted matching text, document name, case link, and relevance score"
    - "Cmd+K palette supports quick document search with OCR text"
    - "Dedicated /suche page offers advanced filtering (case, document type, date range, uploader, tags, OCR status)"
  artifacts:
    - path: "src/lib/embedding/chunker.ts"
      provides: "Paragraph-aware German legal text chunking"
      exports: ["createLegalTextSplitter", "chunkDocument"]
    - path: "src/lib/embedding/embedder.ts"
      provides: "Embedding generation via Ollama"
      exports: ["generateEmbedding", "generateQueryEmbedding", "MODEL_VERSION", "isOllamaAvailable"]
    - path: "src/lib/embedding/vector-store.ts"
      provides: "pgvector CRUD operations via Prisma raw SQL"
      exports: ["insertChunks", "deleteChunks", "searchSimilar"]
    - path: "src/lib/queue/processors/embedding.processor.ts"
      provides: "BullMQ embedding job processor"
      exports: ["processEmbeddingJob"]
    - path: "src/app/(dashboard)/suche/page.tsx"
      provides: "Advanced search page route"
    - path: "src/components/search/search-page.tsx"
      provides: "Search page with filters and rich results"
    - path: "src/components/search/search-result-card.tsx"
      provides: "Rich snippet search result card"
  key_links:
    - from: "src/lib/queue/processors/embedding.processor.ts"
      to: "src/lib/embedding/chunker.ts"
      via: "Chunks document text before embedding"
      pattern: "chunkDocument"
    - from: "src/lib/queue/processors/embedding.processor.ts"
      to: "src/lib/embedding/embedder.ts"
      via: "Generates embeddings for each chunk"
      pattern: "generateEmbedding"
    - from: "src/lib/queue/processors/embedding.processor.ts"
      to: "src/lib/embedding/vector-store.ts"
      via: "Stores chunk embeddings in pgvector"
      pattern: "insertChunks"
    - from: "src/components/search/search-page.tsx"
      to: "/api/search"
      via: "Fetches search results with highlighting"
      pattern: "fetch.*api/search"
---

<objective>
Build the RAG ingestion pipeline (chunking + embedding + pgvector storage) and the search experience (advanced search page + enhanced Cmd+K palette) -- completing the document processing pipeline from upload to AI-ready retrieval.

Purpose: This plan makes documents AI-retrievable for Phase 6's document chat and proactive agent features. It also delivers the user-facing search experience with full-text content search across all OCR'd documents.

Output: Working embedding pipeline that chunks and embeds documents into pgvector, plus a dedicated search page with rich snippet results and an enhanced command palette for quick document search.
</objective>

<execution_context>
@/Users/patrickbaumfalk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/patrickbaumfalk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-document-pipeline-ocr-rag-ingestion/04-RESEARCH.md
@.planning/phases/04-document-pipeline-ocr-rag-ingestion/04-CONTEXT.md
@.planning/phases/04-document-pipeline-ocr-rag-ingestion/04-01-SUMMARY.md
@prisma/schema.prisma
@src/lib/meilisearch.ts
@src/components/layout/command-palette.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Chunker + Embedder + Vector Store + Embedding Processor + Worker Registration</name>
  <files>
    src/lib/embedding/chunker.ts
    src/lib/embedding/embedder.ts
    src/lib/embedding/vector-store.ts
    src/lib/queue/processors/embedding.processor.ts
    src/worker.ts
    prisma/migrations/manual_pgvector_index.sql
    package.json
  </files>
  <action>
    **1. Install dependencies:**
    ```bash
    npm install @langchain/textsplitters @langchain/core pgvector
    ```

    **2. Create German legal text chunker (src/lib/embedding/chunker.ts):**
    Use `RecursiveCharacterTextSplitter` from `@langchain/textsplitters`.

    Define `GERMAN_LEGAL_SEPARATORS`:
    ```typescript
    const GERMAN_LEGAL_SEPARATORS = [
      "\n\nTenor\n",
      "\n\nTatbestand\n",
      "\n\nEntscheidungsgründe\n",
      "\n\nGründe\n",
      "\n\n",   // Standard paragraph break
      "\n",     // Line break
      ". ",     // Sentence boundary
      " ",      // Word boundary
      "",       // Character-level fallback
    ];
    ```

    Export `createLegalTextSplitter()`: returns RecursiveCharacterTextSplitter with:
    - `chunkSize: 1000` (approx 250 tokens for German)
    - `chunkOverlap: 200` (20% overlap for context continuity)
    - `separators: GERMAN_LEGAL_SEPARATORS`

    Export `chunkDocument(text: string): Promise<{ content: string; index: number }[]>`:
    - Create splitter, call `splitText(text)`
    - Return array of `{ content, index }` objects

    **3. Create embedding generator (src/lib/embedding/embedder.ts):**
    Constants:
    - `OLLAMA_URL` from `process.env.OLLAMA_URL ?? "http://localhost:11434"`
    - `EMBEDDING_MODEL` from `process.env.EMBEDDING_MODEL ?? "blaifa/multilingual-e5-large-instruct"`
    - `EMBEDDING_DIMENSIONS = 1024`
    - `MODEL_VERSION = \`${EMBEDDING_MODEL}@1.0\``

    Export `isOllamaAvailable(): Promise<boolean>`:
    - GET `${OLLAMA_URL}/api/tags` with 5s timeout
    - Return true if response OK, false on error (graceful check)

    Export `generateEmbedding(text: string): Promise<number[]>`:
    - Prefix text with `"passage: "` (E5 instruction format for documents)
    - POST to `${OLLAMA_URL}/api/embed` with `{ model: EMBEDDING_MODEL, input: prefixedText }`
    - Return `data.embeddings[0]`
    - Throw descriptive error on failure

    Export `generateQueryEmbedding(query: string): Promise<number[]>`:
    - Prefix with `"query: "` (E5 instruction format for queries)
    - Same API call pattern

    Export `generateEmbeddingsBatch(texts: string[], batchSize?: number): Promise<number[][]>`:
    - Process texts in batches (default batchSize: 5)
    - For each batch, call individual `generateEmbedding()` sequentially (Ollama handles one at a time efficiently)
    - Return array of embedding vectors

    Export `MODEL_VERSION` and `EMBEDDING_DIMENSIONS`.

    **4. Create pgvector store (src/lib/embedding/vector-store.ts):**
    Import `prisma` from `@/lib/db` and `pgvector` npm package.

    Export `insertChunks(dokumentId: string, chunks: { content: string; index: number; embedding: number[] }[], modelVersion: string): Promise<void>`:
    - Delete any existing chunks for this dokumentId first (idempotent re-embedding)
    - For each chunk: use `prisma.$executeRaw` with parameterized SQL:
      ```sql
      INSERT INTO document_chunks (id, dokument_id, chunk_index, content, embedding, model_version, created_at)
      VALUES (gen_random_uuid(), $1, $2, $3, $4::vector, $5, NOW())
      ```
    - Use `pgvector.toSql(embedding)` for vector formatting

    Export `deleteChunks(dokumentId: string): Promise<void>`:
    - `prisma.$executeRaw\`DELETE FROM document_chunks WHERE dokument_id = ${dokumentId}\``

    Export `searchSimilar(queryEmbedding: number[], akteId: string, limit?: number, modelVersion?: string): Promise<{ content: string; dokumentId: string; dokumentName: string; score: number; chunkIndex: number }[]>`:
    - Use cosine similarity: `1 - (embedding <=> $1::vector) as score`
    - Join with dokumente table: get document name
    - Filter by akte_id (case-scoped search)
    - Filter by model_version if provided (important for model upgrades)
    - ORDER BY cosine distance ASC, LIMIT
    - Return results with score, content, document info

    Export `getEmbeddingStats(): Promise<{ totalChunks: number; documentsWithEmbeddings: number; modelVersions: string[] }>`:
    - Aggregate stats for admin dashboard

    **5. Create manual pgvector index migration (prisma/migrations/manual_pgvector_index.sql):**
    ```sql
    -- Run after prisma db push to create vector extension and HNSW index
    -- This file is applied manually since Prisma cannot generate vector operations
    CREATE EXTENSION IF NOT EXISTS vector;

    CREATE INDEX IF NOT EXISTS document_chunks_embedding_idx
      ON document_chunks
      USING hnsw (embedding vector_cosine_ops)
      WITH (m = 16, ef_construction = 64);
    ```
    Note in the file that this should be applied via `psql` or a startup script.

    **6. Create embedding processor (src/lib/queue/processors/embedding.processor.ts):**
    Import types from `src/lib/ocr/types.ts` (EmbeddingJobData).
    Export `processEmbeddingJob(job: Job<EmbeddingJobData>)`:
    - Check Ollama availability via `isOllamaAvailable()`. If not available:
      - Log warning: `"[Embedding] Ollama unavailable, skipping embedding for dokument ${dokumentId}"`
      - Return without error (graceful skip -- do NOT fail the job)
    - Chunk the text using `chunkDocument(job.data.ocrText)`
    - If no chunks produced (empty text), log and return
    - Process chunks in batches of 5:
      - For each chunk, call `generateEmbedding(chunk.content)`
      - Collect `{ content, index, embedding }` tuples
    - Store all chunks via `insertChunks(dokumentId, chunks, MODEL_VERSION)`
    - Log success: `"[Embedding] Embedded ${chunks.length} chunks for dokument ${dokumentId}"`

    **7. Register embedding processor in worker.ts:**
    Import `processEmbeddingJob`.
    Create BullMQ Worker for "document-embedding" queue with concurrency: 1 (memory-intensive).
    Add to graceful shutdown handler.
    Log startup: `"[Worker] document-embedding processor registered"`

    **8. Apply pgvector index:**
    Create a small utility that runs the SQL from the manual migration file. Add to worker startup (after DB connection):
    ```typescript
    // Ensure pgvector extension and HNSW index exist
    await prisma.$executeRawUnsafe(`CREATE EXTENSION IF NOT EXISTS vector`);
    await prisma.$executeRawUnsafe(`
      CREATE INDEX IF NOT EXISTS document_chunks_embedding_idx
      ON document_chunks USING hnsw (embedding vector_cosine_ops)
      WITH (m = 16, ef_construction = 64)
    `);
    ```
    Wrap in try-catch since the extension might already exist. This is idempotent.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer && npx tsc --noEmit --pretty 2>&1 | head -30</automated>
    <manual>Verify chunker splits text correctly, embedder module compiles, vector store has insert/search/delete, embedding processor is registered in worker</manual>
  </verify>
  <done>
    - @langchain/textsplitters and pgvector npm packages installed
    - German legal text chunker produces ~250-token chunks with 20% overlap using legal-specific separators
    - Embedding generator calls Ollama's multilingual-e5-large-instruct with E5 instruction prefixes
    - Vector store provides insert, delete, and cosine similarity search via Prisma raw SQL
    - HNSW index created for efficient vector search
    - Embedding processor chunks text, generates embeddings in batches, stores in pgvector
    - Graceful skip if Ollama is unavailable (does not block pipeline)
    - Embedding worker registered in worker.ts with concurrency 1
  </done>
</task>

<task type="auto">
  <name>Task 2: Search API + Advanced Search Page + Search Result Cards + Command Palette Enhancement</name>
  <files>
    src/app/api/search/route.ts
    src/app/(dashboard)/suche/page.tsx
    src/components/search/search-page.tsx
    src/components/search/search-result-card.tsx
    src/components/layout/command-palette.tsx
  </files>
  <action>
    **1. Create enhanced search API (src/app/api/search/route.ts):**
    GET handler with query params:
    - `q` (search query, required)
    - `akteId` (optional filter)
    - `mimeType` (optional filter)
    - `tags` (optional, comma-separated)
    - `ocrStatus` (optional filter)
    - `dokumentStatus` (optional filter)
    - `createdById` (optional filter)
    - `dateFrom` (optional, ISO date)
    - `dateTo` (optional, ISO date)
    - `limit` (default 20, max 100)
    - `offset` (default 0)

    Auth check. Build Meilisearch filter array from params.

    Call Meilisearch search with:
    - `attributesToHighlight: ["name", "ocrText"]`
    - `highlightPreTag: "<mark>"`, `highlightPostTag: "</mark>"`
    - `attributesToCrop: ["ocrText"]`, `cropLength: 200` (for snippets)
    - All filters applied

    For each result, enrich with:
    - Case info (aktenzeichen, kurzrubrum) from the search record
    - OCR status badge info
    - Relevance score (from Meilisearch `_rankingScore` if available)

    Return: `{ hits: SearchResult[], estimatedTotalHits, processingTimeMs }`

    SearchResult shape: `{ id, name, akteId, aktenzeichen, kurzrubrum, mimeType, ocrStatus, tags, createdByName, createdAt, snippet (highlighted ocrText crop), nameHighlighted, score }`

    **2. Create search result card (src/components/search/search-result-card.tsx):**
    Props: `{ result: SearchResult }`
    Display (per user decision -- Google-style rich snippets):
    - **Title line:** Document name (with highlighted match in name via `nameHighlighted`), clickable link to `/akten/{akteId}/dokumente/{id}`
    - **Meta line:** Case link (aktenzeichen -- kurzrubrum), document type icon, upload date, uploader name
    - **Snippet:** Highlighted matching text from OCR content (using `<mark>` tags rendered as yellow highlight)
    - **Badges:** OCR status badge (OcrStatusBadge component), relevance score as small percentage
    - **Tags:** Colored tag chips if document has tags

    Use Tailwind styling: card with hover state, subtle border, appropriate spacing.
    Handle missing snippets gracefully (show "Kein Textinhalt" for documents without OCR text).

    **3. Create search page (src/components/search/search-page.tsx):**
    "use client" component.
    **Search input:** Large search bar at top with search icon and clear button. Debounced (300ms) search-as-you-type.
    **Filter bar** (collapsible, below search):
    - Akte: Combobox/select with case search (fetch from /api/akten)
    - Dokumenttyp: Select (PDF, DOCX, Bilder, Sonstige)
    - Zeitraum: Date range picker (von/bis)
    - Hochgeladen von: Select (fetch users)
    - Tags: Multi-select from DokumentTagKategorie
    - OCR Status: Select (Alle, Abgeschlossen, Ausstehend, Fehlgeschlagen)
    - Dokumentstatus: Select (Alle, Entwurf, ZurPruefung, Freigegeben, Versendet)
    - "Filter zuruecksetzen" button
    All filters as URL search params (shareable/bookmarkable URLs).

    **Results area:**
    - Loading state: skeleton cards
    - Empty state: "Keine Dokumente gefunden" with suggestion to adjust filters
    - Results: List of SearchResultCard components
    - Stats bar: "{N} Ergebnisse in {X}ms"
    - Pagination: Load more button (offset-based) or infinite scroll

    **4. Create search page route (src/app/(dashboard)/suche/page.tsx):**
    Server component that renders `<SearchPage />`.
    Page metadata: "Dokumentensuche"

    **5. Enhance Command Palette (src/components/layout/command-palette.tsx):**
    Add a "Dokumente durchsuchen" section to the existing command palette:
    - When user types in Cmd+K, in addition to existing commands, search documents via `/api/search?q={query}&limit=5`
    - Show results in a "Dokumente" group within the command palette
    - Each result shows: document name (highlighted), case reference, OCR badge
    - Clicking a result navigates to `/akten/{akteId}/dokumente/{docId}`
    - Add a "Alle Ergebnisse anzeigen" action at bottom that navigates to `/suche?q={query}`
    - Use debounced search (300ms) to avoid excessive API calls

    The existing command palette uses cmdk. Add document results as a new `<CommandGroup heading="Dokumente">` within the existing structure. Only show this group when the search query is 2+ characters.
  </action>
  <verify>
    <automated>cd /Users/patrickbaumfalk/Projekte/AI-Lawyer && npx tsc --noEmit --pretty 2>&1 | head -30</automated>
    <manual>Navigate to /suche -- search for a term, see results with highlighted snippets. Open Cmd+K, type a document name, see document results in palette.</manual>
  </verify>
  <done>
    - Search API returns Meilisearch results with highlighted snippets, all filter params supported
    - Search result cards show Google-style rich snippets (title, case link, highlighted text, badges, tags)
    - Dedicated /suche page has search input with filter bar (case, type, date, uploader, tags, OCR status, document status)
    - Results are paginated with stats display
    - Filters are URL-param based (shareable)
    - Command palette (Cmd+K) shows document search results alongside existing commands
    - "Alle Ergebnisse anzeigen" in palette links to full search page
  </done>
</task>

</tasks>

<verification>
1. `npm install` succeeds with @langchain/textsplitters, @langchain/core, pgvector
2. `npx tsc --noEmit` passes
3. Chunker produces chunks from German legal text with paragraph-aware splitting
4. Embedder calls Ollama API with correct E5 prefixes
5. Vector store inserts and queries embeddings via raw SQL
6. Embedding processor is registered in worker.ts
7. Search API returns highlighted results from Meilisearch
8. /suche page renders with all filters and result cards
9. Cmd+K palette shows document search results
</verification>

<success_criteria>
- Documents are chunked with German legal separators and embedded into pgvector via Ollama
- Model version is tracked per chunk for safe model upgrades
- Embedding pipeline gracefully skips when Ollama is unavailable
- Search page shows rich snippet results with highlighted OCR text matches
- All filters work: case, document type, date range, uploader, tags, OCR status, document status
- Cmd+K palette includes document search results with navigation to detail page
- pgvector HNSW index exists for efficient cosine similarity search
</success_criteria>

<output>
After completion, create `.planning/phases/04-document-pipeline-ocr-rag-ingestion/04-03-SUMMARY.md`
</output>
