# Phase 23.1: Integration Wiring Fixes - Research

**Researched:** 2026-02-27
**Domain:** Cross-phase integration wiring (notification plumbing + multi-turn Schriftsatz pipeline state)
**Confidence:** HIGH

## Summary

This phase closes two specific integration gaps found during the v0.2 milestone audit. The first gap (DRFT-06) is trivial: `update-akte-rag.ts` is the only write tool that does not call `notifyDraftCreated` after creating a HelenaDraft. The fix is a 10-line copy-paste from any of the other 5 write tools that already have this pattern. The second gap (ORCH-04) is substantially more complex: the Schriftsatz pipeline currently returns `{ status: "needs_input", rueckfrage, slotState, intentState }` but there is no mechanism to persist that state, detect follow-up answers, or resume the pipeline. The entire chat flow (`/api/ki-chat` via `useChat`) bypasses the Helena agent entry point, and the Helena agent entry point (`runHelenaAgent`) currently has no way to receive a resumed pipeline context.

The ORCH-04 implementation requires: (1) a new Prisma model for pending pipeline state, (2) a new API endpoint or extension to `/api/ki-chat` that checks for pending state before routing to the normal chat path, (3) LLM-based intent classification to distinguish pipeline answers from unrelated messages, (4) LLM-based free-text-to-slot-values parsing, and (5) frontend-side display of Rueckfragen context with collapsible "Bisherige Angaben" sections.

**Primary recommendation:** Split implementation into two independent work streams: (A) the trivial DRFT-06 notification wiring (< 15 min), and (B) the multi-turn ORCH-04 Rueckfragen flow which itself has multiple sub-tasks (DB schema, API routing, LLM parsing, frontend display).

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions
- **DRFT-06**: Copy the existing `notifyDraftCreated` pattern from the other 5 write-tool sites. Import from `draft-notification.ts` in `update-akte-rag.ts`. Call fire-and-forget after `helenaDraft.create`, same as `create-draft-dokument.ts` etc.
- **ORCH-04 Answer Experience**: Rueckfrage looks like a normal Helena chat bubble -- no special card or styling. Include context of what Helena already knows ("Fuer die Kuendigungsschutzklage (Klaeger: Max Muster) brauche ich noch: ..."). Collapsible "Bisherige Angaben" section below the Rueckfrage showing all filled slots. User can naturally correct earlier slots mid-flow (LLM detects correction and updates). One Rueckfrage at a time.
- **ORCH-04 State Persistence**: Per-user state -- each user has their own independent pending pipeline per Akte, no cross-user interference. One pending pipeline per user per Akte (multiple across different Akten allowed). Database-persisted -- survives page reload and logout. 7-day TTL with notification on expire. Proactive reminder re-displays pending question on Akte open (only for initiator). Proactive reminder includes a "Verwerfen" button.
- **ORCH-04 Resume Mechanism**: Auto-detect intent: LLM classifies if user message is an answer to the pending Rueckfrage or an unrelated request. If unrelated, clear pending state and handle as normal Helena message. If answer, parse free-text into slot values, re-invoke pipeline with `userSlotValues`. Re-run `prefillSlotsFromAkte` on each resume so Akte data changes are reflected. Show progress indicator on resume using existing `onStepUpdate` pattern. If user starts a NEW Schriftsatz request while one is pending: warn "Du hast noch einen offenen Entwurf fuer X. Verwerfen und neu starten?" -- explicit choice.
- **ORCH-04 Round Cap & Completion**: Maximum 5 Rueckfrage rounds before fallback. Show round counter "(3/5)". At cap: create draft with PLATZHALTERs and list them. When all slots are filled: create draft immediately -- no confirmation summary.
- **ORCH-04 Cancellation**: User can type "abbrechen" or click "Verwerfen" button on reminder. Silent clear -- no acknowledgment message.

### Claude's Discretion
- Exact DB schema for pending pipeline state (extend HelenaMemory or new table)
- LLM prompt design for parsing free-text answers into slot values
- LLM prompt for intent classification (answer vs unrelated message)
- Error handling if pipeline resume fails
- How "Bisherige Angaben" collapsible section is implemented (accordion, details tag, etc.)

### Deferred Ideas (OUT OF SCOPE)
None -- discussion stayed within phase scope
</user_constraints>

<phase_requirements>
## Phase Requirements

| ID | Description | Research Support |
|----|-------------|-----------------|
| DRFT-06 | Socket.IO Benachrichtigung an Zustaendigen wenn Helena einen Draft erstellt hat | Direct code pattern: copy `notifyDraftCreated` call from `create-draft-dokument.ts` into `update-akte-rag.ts` after `helenaDraft.create`. All 5 other write tools already have this wired. |
| ORCH-04 | Slot-Filling mit automatischer Rueckfrage bei fehlenden Pflichtfeldern | The slot-filling stage already works and returns `needs_input` with a `rueckfrage`. What is missing is the persistence layer (new `PendingSchriftsatz` model), the resume routing (check pending state before routing user message), the LLM answer-parser (free-text to slot values), and the frontend display (Rueckfrage context bubble). |
</phase_requirements>

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| Prisma ORM | 5.x | New `PendingSchriftsatz` model for pipeline state persistence | Already used for all data models; single source of truth |
| AI SDK (Vercel) | 4.3.19 | `generateObject` for structured LLM calls (intent classification, slot parsing) | Already used in Schriftsatz pipeline for `assembleSchriftsatz` |
| Zod | 3.x | Schema validation for intent classification and slot parsing results | Already used for all Schriftsatz schemas |
| Socket.IO (Emitter) | existing | `notifyDraftCreated` for DRFT-06 | Already wired in 5 other write tools |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| BullMQ | existing | Optional: scheduled cleanup for expired pending pipelines (7-day TTL) | If cron-based TTL cleanup is preferred over query-time cleanup |
| React `<details>` | native HTML | Collapsible "Bisherige Angaben" section | Simplest standards-based approach |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| New `PendingSchriftsatz` Prisma model | Extend `HelenaMemory.content` JSON field | HelenaMemory is per-Akte (not per-user-per-Akte), and JSON fields lose query/TTL/index capabilities. New model is cleaner. |
| AI SDK `generateObject` for slot parsing | Manual regex/NLP parsing | User decisions require natural language correction detection ("Der Klaeger heisst eigentlich Mueller"), which needs LLM intelligence. |
| `<details>` tag | shadcn/ui Accordion | `<details>` is simpler, no extra component needed, but Accordion matches the existing UI toolkit. Use Accordion if available in the component library. |

**Installation:**
```bash
# No new packages needed. All capabilities exist in the current stack.
npx prisma migrate dev  # After adding PendingSchriftsatz model
```

## Architecture Patterns

### Recommended Project Structure
```
src/
├── lib/helena/
│   ├── schriftsatz/
│   │   ├── index.ts                  # Pipeline orchestrator (modify: accept userSlotValues from pending state)
│   │   ├── slot-filler.ts            # Already handles userSlotValues merge (no changes needed)
│   │   ├── pending-pipeline.ts       # NEW: CRUD for PendingSchriftsatz records
│   │   └── answer-parser.ts          # NEW: LLM-based free-text to slot values + intent classification
│   ├── tools/_write/
│   │   └── update-akte-rag.ts        # MODIFY: add notifyDraftCreated call
│   └── index.ts                      # MODIFY: check pending state before Schriftsatz routing
├── app/api/
│   └── ki-chat/
│       └── route.ts                  # MODIFY: check pending pipeline before normal RAG chat
├── components/ki/
│   └── chat-messages.tsx             # MODIFY: render Rueckfrage context + Bisherige Angaben
prisma/
└── schema.prisma                     # ADD: PendingSchriftsatz model
```

### Pattern 1: PendingSchriftsatz Model (Claude's Discretion)
**What:** New Prisma model to persist pipeline state between user interactions.
**When to use:** Every time the Schriftsatz pipeline returns `status: "needs_input"`.
**Recommendation:** Dedicated table (not HelenaMemory extension) because:
1. HelenaMemory is `@unique` on `akteId` (one per Akte), but we need per-user-per-Akte state
2. TTL and index requirements are different from HelenaMemory
3. Clean separation of concerns: memory vs. in-flight pipeline state

```prisma
// Recommended schema
model PendingSchriftsatz {
  id          String   @id @default(cuid())
  userId      String
  user        User     @relation(fields: [userId], references: [id])
  akteId      String
  akte        Akte     @relation(fields: [akteId], references: [id], onDelete: Cascade)

  // Pipeline state
  intentState Json     // Serialized IntentResult
  slotState   Json     // Serialized SlotValues
  rueckfrage  String   @db.Text  // Current question text
  round       Int      @default(1)  // Current round (1-5)
  message     String   @db.Text  // Original user message that triggered the pipeline

  // TTL
  expiresAt   DateTime  // now() + 7 days
  createdAt   DateTime  @default(now())
  updatedAt   DateTime  @updatedAt

  @@unique([userId, akteId])  // One pending pipeline per user per Akte
  @@index([userId])
  @@index([expiresAt])
  @@map("pending_schriftsaetze")
}
```

### Pattern 2: Pending State Check in Message Flow
**What:** Before routing a user message to the RAG chat or ReAct agent, check if there is a pending Schriftsatz pipeline for this user + Akte.
**When to use:** Every incoming message in `/api/ki-chat` (or a dedicated endpoint).

**Current flow:**
```
User message -> /api/ki-chat -> RAG retrieval -> streamText -> response
```

**New flow:**
```
User message -> /api/ki-chat ->
  1. Check PendingSchriftsatz for (userId, akteId)
  2. If pending:
     a. Classify intent: is this an answer or unrelated?
     b. If "abbrechen" keyword or unrelated -> clear pending, continue normal flow
     c. If answer -> parse slots, resume pipeline, return result
  3. If not pending:
     a. Check isSchriftsatzIntent (existing fast heuristic)
     b. If Schriftsatz: route to pipeline (existing)
     c. Else: normal RAG chat (existing)
```

**Key decision point:** Where does the pending check live?
- Option A: In `/api/ki-chat/route.ts` directly (before the RAG pipeline)
- Option B: In `runHelenaAgent` in `src/lib/helena/index.ts` (before the Schriftsatz routing)

**Recommendation: Option A** -- because `/api/ki-chat` is the actual entry point for user messages. `runHelenaAgent` is for the ReAct agent (tool-calling flow) and is only called from the task processor, not from the chat endpoint. The Schriftsatz pipeline is invoked via `runHelenaAgent` for background tasks but for inline chat, the pipeline result needs to be streamed back. The simplest approach is to check pending state early in `/api/ki-chat/route.ts`.

However, there is a subtlety: the current `/api/ki-chat` does NOT use `runHelenaAgent` at all -- it streams directly with `streamText`. The Schriftsatz pipeline routing through `runHelenaAgent` is only triggered via background tasks. This means a Schriftsatz request from the chat UI currently goes through the RAG chat path, not the deterministic pipeline.

**This is actually a deeper integration gap**: the inline chat endpoint has no Schriftsatz pipeline routing. The `isSchriftsatzIntent` check only exists in `runHelenaAgent` which is only called from the task processor. For the multi-turn Rueckfrage flow to work from the chat UI, we need to either:
1. Route Schriftsatz-intent messages from `/api/ki-chat` to `runSchriftsatzPipeline` directly
2. Or add a separate `/api/helena/schriftsatz` endpoint for the chat UI

**Recommendation: Option 1** -- add Schriftsatz detection and pipeline invocation in `/api/ki-chat/route.ts` before the RAG pipeline. This keeps the user experience seamless (same chat input, same UI).

### Pattern 3: LLM Answer Parser (Claude's Discretion)
**What:** Use `generateObject` to classify user intent and extract slot values from free-text answers.
**When to use:** When a pending pipeline exists and the user sends a message.

```typescript
// Intent classification schema
const IntentClassificationSchema = z.object({
  type: z.enum(["answer", "correction", "cancel", "unrelated"]),
  // For corrections: which slot is being corrected
  correctedSlot: z.string().optional(),
});

// Slot extraction schema (dynamic based on missing slots)
const SlotExtractionSchema = z.object({
  extractedValues: z.record(z.string()),
  confidence: z.number(),
});
```

**LLM prompt design recommendations:**
- Keep intent classification prompt minimal -- fast, cheap call
- Include the current Rueckfrage text in the prompt for context
- For slot extraction, list the expected slot with its type and label
- For correction detection, include all current slot values so the LLM can identify contradictions

### Pattern 4: Fire-and-Forget Notification (DRFT-06)
**What:** Exact pattern used in all other write tools.
**Code example from `create-draft-dokument.ts`:**

```typescript
import { notifyDraftCreated } from "@/lib/helena/draft-notification";

// After helenaDraft.create:
const akte = await ctx.prisma.akte.findUnique({
  where: { id: targetAkteId },
  select: { anwaltId: true, sachbearbeiterId: true },
});
const akteAnwaltId = akte?.anwaltId ?? akte?.sachbearbeiterId ?? null;

// Fire-and-forget: notification failure must not fail the tool
notifyDraftCreated(
  { id: draft.id, akteId: targetAkteId, userId: ctx.userId, typ: draft.typ, titel: draft.titel },
  akteAnwaltId,
).catch(() => {});
```

### Anti-Patterns to Avoid
- **Storing pipeline state in HelenaMemory:** HelenaMemory has `@unique akteId` (one per Akte). Pending pipelines are per-user-per-Akte. Mixing concerns leads to data corruption if two users interact with the same Akte.
- **Using Redis for pipeline state:** User decisions require DB persistence (survives page reload, logout, server restart). Redis is volatile.
- **Blocking on notifyDraftCreated:** All existing write tools use `.catch(() => {})` fire-and-forget pattern. Notification failures must never fail the tool execution.
- **Routing resume through `runHelenaAgent`:** The ReAct agent flow is not designed for Schriftsatz pipeline resumption. The pipeline should be invoked directly.
- **Polling for pending state:** Use proactive display on page load (check once), not polling. The pending state only changes when the user sends a message.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Free-text to slot value extraction | Regex parsing for dates, names, amounts | AI SDK `generateObject` with Zod schema | Natural language is too varied -- "letzten Freitag", "den 15. Maerz", "am 15.03.", "Mitte Maerz" all mean dates. LLM handles this. |
| Intent classification (answer vs unrelated) | Keyword matching | AI SDK `generateObject` with IntentClassificationSchema | "Ja, der 15. Maerz" is an answer. "Kannst du die Akte zusammenfassen?" is unrelated. Context-dependent. |
| Notification wiring | Custom event system | Existing `notifyDraftCreated` from `draft-notification.ts` | Already implemented, tested, and used in 5 other sites. |
| TTL cleanup | Manual cron scripts | Prisma `deleteMany` with `expiresAt < now()` filter | Simple query, run opportunistically on read or via existing BullMQ scheduler. |

**Key insight:** The slot parsing and intent classification are inherently LLM problems because user answers are free-text. A deterministic parser would need to handle every possible date format, name variation, and colloquial expression in German.

## Common Pitfalls

### Pitfall 1: Concurrent Schriftsatz Requests on Same Akte
**What goes wrong:** Two users simultaneously start a Schriftsatz for the same Akte. Their pending states interfere.
**Why it happens:** Shared Akte state confusion.
**How to avoid:** The `@@unique([userId, akteId])` constraint on `PendingSchriftsatz` ensures each user has their own independent state. No cross-user interference by design.
**Warning signs:** If you see a `@@unique([akteId])` constraint instead of `@@unique([userId, akteId])`, the model is wrong.

### Pitfall 2: Chat Endpoint Does Not Route to Schriftsatz Pipeline
**What goes wrong:** The multi-turn Rueckfrage flow never triggers because `/api/ki-chat` does not invoke the Schriftsatz pipeline at all -- it goes straight to RAG + `streamText`.
**Why it happens:** The Schriftsatz routing only exists in `runHelenaAgent` (background task path). The inline chat path (`/api/ki-chat`) is a separate code path.
**How to avoid:** Add Schriftsatz intent detection and pipeline invocation in `/api/ki-chat/route.ts` as an early return before the RAG pipeline. This is the critical integration gap.
**Warning signs:** Testing the chat UI with a Schriftsatz request and getting a RAG-based response instead of a structured pipeline response.

### Pitfall 3: Expired Pending State Confusion
**What goes wrong:** User returns after 8 days, types an answer to a Rueckfrage, but the pending state has expired. The message goes to the RAG chat and produces a confusing response.
**Why it happens:** TTL expired but no notification was sent (or user ignored it).
**How to avoid:** On message receipt, check for pending state. If not found but the message looks like a slot answer, Helena can say "Ich habe keine offene Rueckfrage gefunden. Moechtest du einen neuen Schriftsatz starten?" Proactive expiry notification ("Dein Entwurf fuer X ist abgelaufen") should fire via a scheduled check.
**Warning signs:** Users reporting "Helena forgot my Schriftsatz" after a few days.

### Pitfall 4: Stale Akte Data After Slot Correction
**What goes wrong:** User corrects a slot value (e.g., Klaeger name), but the old pre-filled value from the Akte overrides the correction on resume.
**Why it happens:** `prefillSlotsFromAkte` is called on each resume (per user decision), and pre-filled values might overwrite user corrections.
**How to avoid:** The existing `fillSlots` function already handles this correctly: "user-provided values always override pre-filled values." The key is to ensure that `userSlotValues` (which includes corrections) is passed as the `userProvided` parameter, not merged into `prefilled`. The merge order in `fillSlots` is: `userProvided > prefilled > null`. So corrections persist as long as they are in the `userSlotValues` object.
**Warning signs:** Slot values reverting to Akte data after a resume.

### Pitfall 5: Non-Streaming Pipeline Response in Streaming Chat
**What goes wrong:** The Schriftsatz pipeline returns a JSON result, but `/api/ki-chat` streams text via `streamText`. The pipeline result needs to be sent back in a format the chat UI can display.
**Why it happens:** The pipeline is not a streaming operation -- it produces a final result.
**How to avoid:** For `needs_input` results, return the Rueckfrage text as a non-streaming `NextResponse.json()` with a flag, or convert to a simulated stream. The simplest approach: return the pipeline result as a structured JSON response with a `type: "schriftsatz"` discriminator, and handle it in the frontend. Alternatively, use AI SDK's `streamText` with a pre-baked message to maintain the streaming contract.
**Warning signs:** Chat UI showing raw JSON or crashing when the pipeline returns a result.

## Code Examples

### DRFT-06: Complete Fix for update-akte-rag.ts

```typescript
// Source: existing pattern in create-draft-dokument.ts, create-notiz.ts, etc.
// File: src/lib/helena/tools/_write/update-akte-rag.ts

import { notifyDraftCreated } from "@/lib/helena/draft-notification";

// Inside execute(), after helenaDraft.create:
const draft = await ctx.prisma.helenaDraft.create({ ... });

// ADD: Resolve Akte owner for notification recipients
const akte = await ctx.prisma.akte.findUnique({
  where: { id: targetAkteId },
  select: { anwaltId: true, sachbearbeiterId: true },
});
const akteAnwaltId = akte?.anwaltId ?? akte?.sachbearbeiterId ?? null;

// ADD: Fire-and-forget notification
notifyDraftCreated(
  { id: draft.id, akteId: targetAkteId, userId: ctx.userId, typ: draft.typ, titel: draft.titel },
  akteAnwaltId,
).catch(() => {});
```

### ORCH-04: Pending Pipeline CRUD Service

```typescript
// File: src/lib/helena/schriftsatz/pending-pipeline.ts

import { prisma } from "@/lib/db";
import type { IntentResult } from "./schemas";
import type { SlotValues } from "./slot-filler";

const TTL_DAYS = 7;

export async function savePendingPipeline(params: {
  userId: string;
  akteId: string;
  intentState: IntentResult;
  slotState: SlotValues;
  rueckfrage: string;
  round: number;
  message: string;
}) {
  const expiresAt = new Date(Date.now() + TTL_DAYS * 24 * 60 * 60 * 1000);

  return prisma.pendingSchriftsatz.upsert({
    where: {
      userId_akteId: {
        userId: params.userId,
        akteId: params.akteId,
      },
    },
    create: {
      userId: params.userId,
      akteId: params.akteId,
      intentState: params.intentState as any,
      slotState: params.slotState as any,
      rueckfrage: params.rueckfrage,
      round: params.round,
      message: params.message,
      expiresAt,
    },
    update: {
      intentState: params.intentState as any,
      slotState: params.slotState as any,
      rueckfrage: params.rueckfrage,
      round: params.round,
      expiresAt,
    },
  });
}

export async function loadPendingPipeline(userId: string, akteId: string) {
  const pending = await prisma.pendingSchriftsatz.findUnique({
    where: { userId_akteId: { userId, akteId } },
  });

  if (!pending) return null;

  // TTL check
  if (pending.expiresAt < new Date()) {
    await prisma.pendingSchriftsatz.delete({
      where: { id: pending.id },
    });
    return null;
  }

  return pending;
}

export async function clearPendingPipeline(userId: string, akteId: string) {
  await prisma.pendingSchriftsatz.deleteMany({
    where: { userId, akteId },
  });
}
```

### ORCH-04: Intent Classification + Slot Extraction

```typescript
// File: src/lib/helena/schriftsatz/answer-parser.ts

import { generateObject } from "ai";
import { z } from "zod";
import { getModel } from "@/lib/ai/provider";

const IntentSchema = z.object({
  type: z.enum(["answer", "correction", "cancel", "unrelated"]),
  correctedSlotKey: z.string().optional(),
});

export async function classifyAnswerIntent(
  userMessage: string,
  pendingRueckfrage: string,
  currentSlots: Record<string, unknown>,
) {
  const model = await getModel();

  const { object } = await generateObject({
    model,
    schema: IntentSchema,
    prompt: `Du bist ein Intent-Classifier. Der Nutzer hat eine offene Rueckfrage in einem Schriftsatz-Pipeline:

Aktuelle Rueckfrage: "${pendingRueckfrage}"

Bisherige Angaben: ${JSON.stringify(currentSlots, null, 2)}

Nachricht des Nutzers: "${userMessage}"

Klassifiziere die Nachricht:
- "answer": Der Nutzer beantwortet die Rueckfrage
- "correction": Der Nutzer korrigiert eine fruehere Angabe (nenne den Slot-Key in correctedSlotKey)
- "cancel": Der Nutzer moechte abbrechen (z.B. "abbrechen", "stop", "vergiss es")
- "unrelated": Der Nutzer stellt eine andere Frage die nichts mit dem Schriftsatz zu tun hat`,
  });

  return object;
}
```

### ORCH-04: Rueckfrage Display in Chat (Frontend)

```tsx
// In chat-messages.tsx: Render Rueckfrage with context
// Use <details> for the collapsible "Bisherige Angaben" section

function RueckfrageMessage({ text, filledSlots, round, maxRounds }: {
  text: string;
  filledSlots: Record<string, unknown>;
  round: number;
  maxRounds: number;
}) {
  const slotEntries = Object.entries(filledSlots)
    .filter(([, v]) => v !== null);

  return (
    <div>
      <p>{text} <span className="text-xs text-muted-foreground">({round}/{maxRounds})</span></p>
      {slotEntries.length > 0 && (
        <details className="mt-2 text-sm text-muted-foreground">
          <summary className="cursor-pointer hover:text-foreground">
            Bisherige Angaben ({slotEntries.length})
          </summary>
          <ul className="mt-1 ml-4 list-disc">
            {slotEntries.map(([key, value]) => (
              <li key={key}><strong>{key}:</strong> {String(value)}</li>
            ))}
          </ul>
        </details>
      )}
    </div>
  );
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Pipeline returns needs_input and discards state | Pipeline returns state but nothing persists it | Phase 22 (current) | Multi-turn impossible -- user must provide all info in one message |
| No chat-to-pipeline routing | `isSchriftsatzIntent` in `runHelenaAgent` | Phase 22 | Only works for background tasks, not inline chat |

**Current gap:** The pipeline's `userSlotValues` parameter exists in the function signature but is never passed from any call site because there is no state persistence layer.

## Open Questions

1. **How should the pipeline result be returned to the streaming chat UI?**
   - What we know: `/api/ki-chat` uses AI SDK `streamText` which returns a streaming response. The Schriftsatz pipeline returns a JSON object.
   - What's unclear: Should we return the pipeline result as a non-streaming JSON response (different response format), or wrap it in a simulated stream? Or use a separate endpoint?
   - Recommendation: Return as JSON with a `type: "schriftsatz_rueckfrage"` field. Frontend detects this in `onResponse` and renders differently than streamed text. This avoids complex stream simulation. For the final draft result, the pipeline already creates a HelenaDraft and the notification flow handles the rest.

2. **Where to run TTL cleanup for expired pending pipelines?**
   - What we know: BullMQ has a scheduler for cron jobs (used for the scanner in Phase 24). Alternatively, cleanup can be lazy (on read).
   - What's unclear: Whether to add a dedicated cleanup job or rely on lazy cleanup.
   - Recommendation: Lazy cleanup on read (check `expiresAt` in `loadPendingPipeline`). Add a weekly BullMQ cron for orphaned records only if Phase 24 scanner is implemented. No premature optimization.

3. **Should the "new Schriftsatz while pending" warning be handled in the frontend or backend?**
   - What we know: User decided on explicit warning: "Du hast noch einen offenen Entwurf fuer X. Verwerfen und neu starten?"
   - What's unclear: Where the check lives.
   - Recommendation: Backend check in the Schriftsatz routing logic. If `isSchriftsatzIntent(message)` and `loadPendingPipeline()` returns a record, return a special response with the warning text and two action options (verwerfen + neu starten, or zurueck zur Rueckfrage). Frontend renders the choice.

## Sources

### Primary (HIGH confidence)
- **Codebase analysis:** `src/lib/helena/tools/_write/update-akte-rag.ts` -- confirmed missing `notifyDraftCreated` call (line 61-78, no notification after draft creation)
- **Codebase analysis:** `src/lib/helena/tools/_write/create-draft-dokument.ts` -- confirmed pattern (lines 56-67)
- **Codebase analysis:** `src/lib/helena/tools/_write/create-notiz.ts` -- confirmed pattern (lines 53-64)
- **Codebase analysis:** `src/lib/helena/tools/_write/create-draft-frist.ts` -- confirmed pattern (lines 75-85)
- **Codebase analysis:** `src/lib/helena/tools/_write/create-draft-zeiterfassung.ts` -- confirmed pattern (lines 77-85)
- **Codebase analysis:** `src/lib/helena/schriftsatz/index.ts` -- confirmed `userSlotValues` parameter exists but is never passed from any call site with actual values (line 45, 163, 197)
- **Codebase analysis:** `src/lib/helena/index.ts` -- confirmed `isSchriftsatzIntent` routing only in `runHelenaAgent` (lines 184-254), NOT in `/api/ki-chat/route.ts`
- **Codebase analysis:** `src/app/api/ki-chat/route.ts` -- confirmed no Schriftsatz pipeline routing, only RAG + streamText
- **Codebase analysis:** `src/lib/helena/schriftsatz/slot-filler.ts` -- confirmed `fillSlots` merge order: user-provided > pre-filled > null (lines 184-194)
- **Codebase analysis:** `prisma/schema.prisma` -- confirmed HelenaMemory has `@unique akteId` (line 1983), confirming it cannot hold per-user state

### Secondary (MEDIUM confidence)
- **AI SDK generateObject:** Verified from codebase usage in `rag-assembler.ts` and other files that `generateObject` with Zod schemas is the established pattern for structured LLM outputs in this project.

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH -- all libraries already in use, no new dependencies
- Architecture: HIGH -- patterns directly derived from codebase analysis, data model constraints verified
- Pitfalls: HIGH -- identified from actual code paths and data flow analysis

**Research date:** 2026-02-27
**Valid until:** 2026-03-27 (stable -- internal integration, no external dependency changes)
